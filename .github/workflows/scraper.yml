name: E-Play Contracts Scraper

on:
  schedule:
    # Run daily at 2 AM UTC (adjust timezone as needed)
    - cron: '0 2 * * *'
  workflow_dispatch:  # Allow manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        pip install curl_cffi gspread google-auth playwright
        playwright install chromium
    
    - name: Run scraper
      env:
        CF_CLEARANCE: ${{ secrets.CF_CLEARANCE }}
        GA_COOKIE: ${{ secrets.GA_COOKIE }}
        GA_ZH4G2KK1JY: ${{ secrets.GA_ZH4G2KK1JY }}
        UPLOAD_TO_SHEETS: ${{ secrets.UPLOAD_TO_SHEETS }}
        SHEETS_CREDENTIALS_JSON: ${{ secrets.SHEETS_CREDENTIALS_JSON }}
        SHEETS_SPREADSHEET_NAME: ${{ secrets.SHEETS_SPREADSHEET_NAME }}
        SHEETS_WORKSHEET_NAME: ${{ secrets.SHEETS_WORKSHEET_NAME }}
        AUTO_REFRESH_COOKIES: ${{ secrets.AUTO_REFRESH_COOKIES }}
      run: |
        cd e-play-scraper
        # Use auto-cookie version if AUTO_REFRESH_COOKIES is enabled
        if [ "$AUTO_REFRESH_COOKIES" = "true" ]; then
          echo "Using automated cookie refresh..."
          python cloud_scraper_auto_cookies.py
        else
          echo "Using manual cookies from secrets..."
          python cloud_scraper.py
        fi
